{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Майнор по Анализу Данных, Группа ИАД-2\n",
    "## 22/03/2017  Деревья решений, случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интро"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='https://eight2late.files.wordpress.com/2016/02/7214525854_733237dd83_z1.jpg?w=700'><center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формально, дерево решений - это связный ациклический граф. В нем можно выделить 3 типа вершин:\n",
    "1. Корневая вершина (root node) -  откуда все начинается\n",
    "2. Внутренние вершины (intermediate nodes)\n",
    "3. Листья (leafs) - самые глубокие вершины дерева, в которых содержится \"ответ\"\n",
    "\n",
    "Во внутренней или коневой вершине признак проверяется на некий логический критерий, по результатам которого мы движемся все глубже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обобщенный псевдокод алгоритма построения дерева\n",
    "\n",
    "\n",
    "```{python}\n",
    "function decision_tree(X, y):\n",
    "\n",
    "    if stopping_criterion(X, y) == True:\n",
    "    \n",
    "        S = create_leaf_with_prediction(y)\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        S = create_node()\n",
    "        (X_1, y_1) .. (X_L, y_L) = best_split(X, y)\n",
    "        \n",
    "        for i in 1..L:\n",
    "            C = decision_tree(X_i, y_i)\n",
    "            connect_nodes(S, C)\n",
    "    return S     \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопрос: как определяются лучшие разбиения (best splits)?\n",
    "#### Шаг1: выбираем меру неопределенности (impurity measures)\n",
    "\n",
    "Пусть $p_k$ - это доля класса $C_k$ в узле дерева $S$.\n",
    "\n",
    "1. Missclassification error  \n",
    "$$I(S) = 1 - \\max\\limits_k p_k $$\n",
    "2. Gini index \n",
    "$$I(S) = 1 - \\sum\\limits_k (p_k)^2 = \\sum\\limits_{k'\\neq k} p_{k'} p_k$$\n",
    "3. Entropy \n",
    "$$I(S) = -\\sum\\limits_k p_k \\log(p_k)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_impurities():\n",
    "    p = np.linspace(0, 1, 100)\n",
    "    p = np.c_[p, 1-p]\n",
    "\n",
    "    missclass = 1 - p.max(axis=1)\n",
    "    plt.plot(p[:,0], missclass, label = 'missclassification error')\n",
    "\n",
    "    gini = 1 - (p ** 2).sum(axis=1)\n",
    "    plt.plot(p[:,0], gini, label = 'gini index')\n",
    "\n",
    "    entropy = - np.nansum((p*np.log2(p)), axis=1)\n",
    "    plt.plot(p[:,0], entropy, label = 'entropy')\n",
    "\n",
    "    plt.xlabel('$p_k$')\n",
    "    plt.ylabel('$I(S)$')\n",
    "    # plt.legend(loc=2, bbox_to_anchor=(0.,0.))\n",
    "    plt.legend(loc=2, bbox_to_anchor=(-0.3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_impurities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг 2: Считаем прирост \"информации\" (определенности)\n",
    "\n",
    "Выберем признак $A$ и пороговое значение $t$ на нем таким образом, чтобы уменьшить неопределенность:\n",
    "\n",
    "**Насколько уменьшится неопределенность:** <br/>\n",
    "$$ Gain(S, A) = I(S) - \\left(\\frac{|S_L|}{|S|}\\cdot I(S_L) + \\frac{|S_R|}{|S|}\\cdot I(S_R) \\right),$$ где $S_R$ и $S_L$ - это потомки узла $S$ c объектами, удовлетворяющим соответствующим условиям.\n",
    "\n",
    "**Замечания:**\n",
    "* Стратегия выбора - жадная\n",
    "* Как определяется порог при вещественных признаках?\n",
    "* Локальная оптимизация - уменьшение Impurity внутри узла\n",
    "* Результаты не сильно зависят от выбора самой меры неопределенности\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "Воспользуемся данными про вино, которые мы видели в ДЗ№0\n",
    "\n",
    "Имплементируйте понравившаюся вам меру неопределенности и посмотрите, где будет находится оптимальный порог."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impurity_measure(p):\n",
    "    # Здесь надо внести исправления\n",
    "    # Выберите меру неопределенности и имплементируйте ее\n",
    "    # Так как у нас задача классификации на 2 класса, то p - это массив из двух значений\n",
    "    return 0\n",
    "\n",
    "def wine_demo():\n",
    "    # Данные\n",
    "    df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
    "\n",
    "    # Рисовалка\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    # Заменяем целевую переменную на класс (хорошее-плохое вино)\n",
    "    df_wine.loc[:, 'quality_cat'] = (df_wine.loc[:, 'quality'] > 5).astype(int) \n",
    "    idx = df_wine.loc[:, 'quality_cat'] == 1\n",
    "    df_wine.loc[idx, 'alcohol'].hist(label='good quality', bins=20, alpha = 0.4, ax=ax[0])\n",
    "    df_wine.loc[~idx, 'alcohol'].hist(label='bad quality', bins=20, alpha = 0.4, ax=ax[0])\n",
    "    ax[0].set_xlabel('alcohol')\n",
    "    \n",
    "    # \n",
    "    p = np.array([df_wine.quality_cat.mean(), 1-df_wine.quality_cat.mean()])\n",
    "\n",
    "    \n",
    "    init_impurity = impurity_measure(p)\n",
    "    \n",
    "    # Зададим значения порогов\n",
    "    t_range = np.linspace(df_wine.alcohol.min(), df_wine.alcohol.max(), 100)\n",
    "    # В этом списке будут хранится величины Gain для каждого порога\n",
    "    G = []\n",
    "\n",
    "    for t in t_range:\n",
    "        idx = df_wine.alcohol < t\n",
    "        p1 = np.array([df_wine.loc[idx, 'quality_cat'].mean(), 1-df_wine.loc[idx, 'quality_cat'].mean()])\n",
    "        p2 = np.array([df_wine.loc[~idx, 'quality_cat'].mean(), 1-df_wine.loc[~idx, 'quality_cat'].mean()])\n",
    "        \n",
    "        #\n",
    "        G.append(init_impurity - (idx.mean()*impurity_measure(p1) + (1-idx.mean())*impurity_measure(p2)))\n",
    "\n",
    "    ax[1].plot(t_range, G)\n",
    "    ax[1].set_xlabel('alcohol')\n",
    "    ax[1].set_ylabel('Gain')\n",
    "\n",
    "    mG = np.nanmax(G)\n",
    "    mt = t_range[np.nanargmax(G)]\n",
    "\n",
    "    ax[0].vlines(mt, 0, 150, label='best threshold (%.2f)' % mt)\n",
    "    ax[1].vlines(mt, 0, mG, label='best threshold\\n(gain = %.4f)' % mG)\n",
    "    \n",
    "    ax[0].legend()\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы демо полностью работало, вам надо установить пакет для визуализации графов [`graphviz`](http://www.graphviz.org/). Если у вас его еще нет, но вы захотите видеть такие картинки - сделайте это, пожалуйста, дома."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from ipywidgets import interact, IntSlider\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def demo_dec_tree(depth=1):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    fig.set_figheight(5)\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    C = np.array([[0., -0.7], [1.5, 0.7]])\n",
    "    gauss1 = np.dot(np.random.randn(200, 2) + np.array([4, 2]), C)\n",
    "    gauss2 = np.dot(np.random.randn(300, 2), C)\n",
    "\n",
    "    X = np.vstack([gauss1, gauss2])\n",
    "    y = np.r_[np.ones(200), np.zeros(300)]\n",
    "\n",
    "    ax[1].scatter(X[:,0], X[:, 1], c=y)\n",
    "    ax[1].set_xlabel('$x_1$')\n",
    "    ax[1].set_ylabel('$x_2$')\n",
    "\n",
    "    # Dec Tree Stuff\n",
    "    tree = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=123)\n",
    "    tree.fit(X,y)\n",
    "\n",
    "    x_range = np.linspace(X.min(), X.max(), 100)\n",
    "    xx1, xx2 = np.meshgrid(x_range, x_range)\n",
    "\n",
    "    Y = tree.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "    Y = Y.reshape(xx1.shape)\n",
    "\n",
    "    ax[1].contourf(xx1, xx2, Y, alpha=0.3)\n",
    "    ax[1].scatter(X[:,0], X[:,1],c=y)\n",
    "    \n",
    "    try:\n",
    "        with open('tree.dot', 'w') as fout:\n",
    "            export_graphviz(tree, out_file=fout, feature_names=['x1', 'x2'], class_names=['0', '1'])\n",
    "        command = [\"dot\", \"-Tpng\", \"tree.dot\", \"-o\", \"tree.png\"]\n",
    "        subprocess.check_call(command)\n",
    "        ax[0].imshow(plt.imread('tree.png'))\n",
    "        ax[0].axis(\"off\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    fig = interact(demo_dec_tree, depth=IntSlider(min=1, max=5, value=1))\n",
    "except:\n",
    "    print 'Что-то не так. Посмотрите на доску'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи регрессии в качестве меры неопределенности могут выступать\n",
    "\n",
    "* Среднее квадратичное отклонение от среднего\n",
    "$$ I(S) = \\frac{1}{|S|}\\sum\\limits_{i \\in S}(y_i - \\bar{y_S})^2 $$\n",
    "* Среднее абсолютное отклонение от медианы\n",
    "$$ I(S) = \\frac{1}{|S|}\\sum\\limits_{i \\in S}|y_i - \\bar{y_S}| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "x_true = np.arange(-5, 5, 0.2)\n",
    "x = x_true + np.random.rand(x_true.shape[0]) - 0.5\n",
    "y_true = np.sin(x_true)+x_true/3\n",
    "y = y_true + np.random.rand(x_true.shape[0]) - 0.5\n",
    "\n",
    "def plot_dec_reg(depth=1, criterion='mse', ):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    fig.set_figheight(5)\n",
    "    \n",
    "    tree = DecisionTreeRegressor(criterion=criterion, max_depth=depth)\n",
    "    tree.fit(x.reshape(-1,1), y)\n",
    "    y_hat = tree.predict(x_true.reshape(-1,1))\n",
    "    \n",
    "    ax[1].plot(x_true, y_true, c='g', label='$f(x)$')\n",
    "    ax[1].scatter(x, y, label='actual data')\n",
    "    ax[1].set_xlabel('x_1')\n",
    "    ax[1].set_ylabel('y')\n",
    "    ax[1].plot(x_true, y_hat, c='r', label='decision tree \\nregression')\n",
    "    ax[1].legend(loc=2)\n",
    "    \n",
    "    try:\n",
    "        with open('tree.dot', 'w') as fout:\n",
    "            export_graphviz(tree, out_file=fout, feature_names=['x1', 'x2'], class_names=['0', '1'])\n",
    "        command = [\"dot\", \"-Tpng\", \"tree.dot\", \"-o\", \"tree.png\"]\n",
    "        subprocess.check_call(command)\n",
    "        ax[0].imshow(plt.imread('tree.png'))\n",
    "        ax[0].axis(\"off\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    fig = interact(plot_dec_reg, depth=IntSlider(min=1, max=5, value=1), criterion=['mse', 'mae'])\n",
    "except:\n",
    "    print 'Что-то не так. Посмотрите на доску'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как определяется предсказание?\n",
    "\n",
    "* Классификация\n",
    "    * Класс с большинством в листе\n",
    "    * Доли каждого из классов в листе\n",
    "* Регрессия\n",
    "    * Среднее (медиана) целевой переменной в листе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преимущества/Недостатки?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл с [данными](https://cloud.mail.ru/public/HoTX/NjK4v8LWx).\n",
    "\n",
    "Представьте, что вы отвечаете за продвижение детских товаров в одном из магазинов некоторой ритейловой сети. Это значит, что вам нужно сделать так, чтобы подгузники, питательные смеси, соски, игрульки, коляски, манежи и прочией товары, расходились как можно лучше.\n",
    "\n",
    "Из исследований фокус-группы вы выяснили, что молодые родители привыкают к брендам тех или иных детских товаров довольно быстро. Вам бы хотелось, чтобы потенциальным покупателям понравилось именно в вашем магазине - можно дать им скидку заранее и обеспечить первое место в их списке магазинов. Вот только как определить, что родители ждут ребенка?\n",
    "\n",
    "Нужна модель!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_retail = pd.read_csv('Retail.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_retail.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "* Оцените долю положительного класса в данных\n",
    "* Разделите данные на обучающую и контрольную выборку случайным образом в пропорции 80/20 (можно c сохранением пропорции классов)\n",
    "* Вы должны получить матрицы X_train, X_test и  ответы к ним.\n",
    "* Как бороться с таким дисбалансом в долях классов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "* Сфокусируемся на гиперпараметре \"глубина дерева\"\n",
    "* С помощью кросс-валидации определите наилучшее значение этого параметра\n",
    "* Попробуйте воспользоваться валидационными кривыми для выбора лучшего значения этого параметра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "try:\n",
    "    from sklearn.model_selection import validation_curve\n",
    "except ImportError:\n",
    "    from sklearn.learning_curve import validation_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Важность признаков\n",
    "\n",
    "В деревьях решений производится автоматический отбор признаков.\n",
    "\n",
    "Пусть $v(S)$ - это признак, который использовался для ветвления в узле $S$\n",
    "\n",
    "$$ \\text{imp}(A) = \\sum\\limits_{i: v(S_i) = A} \\frac{|S_i|}{|S|} Gain(S_i, A) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "* Обучите модель на обучающей выборке\n",
    "* Найдите наиболее важные признаки с помощью `model.feature_importances_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "* Выполните предсказание на контрольной выборке\n",
    "* Оцените всевозможные меры качества. Сравните с тем, что было на этапе кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging - это параллельный способ построения ансамбля.<br/>\n",
    "1. Обучающая выборка сэмплируется $k$ раз с помощью *bootstrap'a* (выборка с возвратом)\n",
    "2. На каждом сэмпле обучается отдельная **базовая модель**\n",
    "3. Ответы моделей усредняются (возможно с весом)\n",
    "<center><img src='http://image.slidesharecdn.com/ipbimprovingthemodelspredictivepowerwithensembleapproaches-121203224610-phpapp02/95/improving-the-models-predictive-power-with-ensemble-approaches-10-638.jpg?cb=1354575467' width='750'></center>\n",
    "\n",
    "*Вопрос: Какая доля объектов в среднем попадает в один bootstrap сэмпл?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Так же есть некоторые обобщения этого подхода:\n",
    "\n",
    "* Метод случайных подпространств - на шаге 1. сэмплируются не только объекты, но и подпространство признаков\n",
    "* Метод случайного леса - на каждом узле сэмплируется подпространство признаков\n",
    "\n",
    "В данном случае, на каждом сэмпле базовой моделью является дерево решений.<br/>\n",
    "Если вам нужно за минимальное время построить достаточно точную и устойчивую модель - это ваш вариант."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "* Проделайте предыдущие этапы для модели случайного леса\n",
    "* Сравние меры качества\n",
    "* Почему результаты оказались лучше (должны были)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "698px",
   "left": "0px",
   "right": "1236.33px",
   "top": "107px",
   "width": "193px"
  },
  "widgets": {
   "state": {
    "0c83da0244f746ee8571d54685224214": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "6d0aac5ed9254107be23aedbbf691ea0": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
